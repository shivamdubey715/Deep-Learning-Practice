{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Import required libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# b. Upload / access the dataset\n",
    "# For this example, let's use the MNIST dataset to detect anomalies\n",
    "# We'll consider digits 0-4 as \"normal\" and digits 5-9 as \"anomalies\"\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize and reshape the dataset\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "x_train = x_train.reshape((x_train.shape[0], -1))  # Flatten the images\n",
    "x_test = x_test.reshape((x_test.shape[0], -1))\n",
    "\n",
    "# Select only \"normal\" data for training\n",
    "x_train_normal = x_train[y_train <= 4]  # Digits 0-4 are considered \"normal\"\n",
    "\n",
    "# Split the normal data into training and validation sets\n",
    "x_train_normal, x_val_normal = train_test_split(x_train_normal, test_size=0.2, random_state=42)\n",
    "\n",
    "# c. Encoder converts it into latent representation\n",
    "# Define the autoencoder model\n",
    "encoding_dim = 32  # Size of the latent representation\n",
    "\n",
    "# Input layer\n",
    "input_layer = Input(shape=(x_train_normal.shape[1],))\n",
    "\n",
    "# Encoder part\n",
    "encoder = Dense(128, activation='relu')(input_layer)\n",
    "encoder = Dense(64, activation='relu')(encoder)\n",
    "encoder_output = Dense(encoding_dim, activation='relu')(encoder)\n",
    "\n",
    "# d. Decoder networks convert it back to the original input\n",
    "# Decoder part\n",
    "decoder = Dense(64, activation='relu')(encoder_output)\n",
    "decoder = Dense(128, activation='relu')(decoder)\n",
    "decoder_output = Dense(x_train_normal.shape[1], activation='sigmoid')(decoder)\n",
    "\n",
    "# Complete autoencoder model\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder_output)\n",
    "\n",
    "# Encoder model for anomaly detection\n",
    "encoder_model = Model(inputs=input_layer, outputs=encoder_output)\n",
    "\n",
    "# e. Compile the models with Optimizer, Loss, and Evaluation Metrics\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['accuracy'])\n",
    "\n",
    "# Train the autoencoder on normal data\n",
    "history = autoencoder.fit(\n",
    "    x_train_normal, x_train_normal,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    validation_data=(x_val_normal, x_val_normal),\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Evaluate the model on test data (to check for reconstruction loss)\n",
    "x_test_normal = x_test[y_test <= 4]  # Normal samples in test set\n",
    "x_test_anomalous = x_test[y_test > 4]  # Anomalous samples in test set\n",
    "\n",
    "# Calculate reconstruction error\n",
    "reconstructions = autoencoder.predict(x_test_normal)\n",
    "mse_normal = mean_squared_error(x_test_normal, reconstructions)\n",
    "\n",
    "reconstructions_anomalous = autoencoder.predict(x_test_anomalous)\n",
    "mse_anomalous = mean_squared_error(x_test_anomalous, reconstructions_anomalous)\n",
    "\n",
    "print(f\"Mean Squared Error for Normal Test Data: {mse_normal:.4f}\")\n",
    "print(f\"Mean Squared Error for Anomalous Test Data: {mse_anomalous:.4f}\")\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "# Detect anomalies using a threshold on reconstruction error\n",
    "threshold = mse_normal + 0.02  # Set an appropriate threshold based on validation\n",
    "\n",
    "# Predict anomalies in the test set\n",
    "reconstruction_errors = np.mean(np.power(x_test - autoencoder.predict(x_test), 2), axis=1)\n",
    "anomalies = reconstruction_errors > threshold\n",
    "\n",
    "# Display the proportion of anomalies detected\n",
    "print(\"Anomaly Detection Results\")\n",
    "print(f\"Total samples: {x_test.shape[0]}\")\n",
    "print(f\"Detected anomalies: {np.sum(anomalies)}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
